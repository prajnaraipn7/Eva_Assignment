{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eva_Assignment7b.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCT66Ax_Dvcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "% matplotlib inline\n",
        "np.random.seed(2017) \n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgCcKJOED4hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
        "num_train, img_channels, img_rows, img_cols =  train_features.shape\n",
        "num_test, _, _, _ =  test_features.shape\n",
        "num_classes = len(np.unique(train_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLgTzlDPD6of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = train_features.astype('float32')/255\n",
        "test_features = test_features.astype('float32')/255\n",
        "# convert class labels to binary class labels\n",
        "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = np_utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0R8HHQbD9xI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMH4QyKtEACe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(test_x, test_y, model):\n",
        "    result = model.predict(test_x)\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJSUW2u2ECIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import  Lambda\n",
        "def space_to_depth_x2(x):\n",
        "    return tf.space_to_depth(x, block_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts6pi7hSLpB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgsnBOucEEZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_height, img_width, channel = train_features.shape[1],train_features.shape[2],train_features.shape[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfqlikobEHFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input\n",
        "input = Input(shape=(img_height, img_width, channel))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z-O8B6SLy0F",
        "colab_type": "code",
        "outputId": "02dc8288-ec28-4fbf-fec2-d4e40ad31167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_2:0' shape=(?, 32, 32, 3) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1IyX_yHEJCM",
        "colab_type": "code",
        "outputId": "17d1c985-9701-4f34-ec25-4fe17ce20717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,SeparableConv2D\n",
        "from keras.layers import concatenate\n",
        "\n",
        "\n",
        "#5,5 seperable convolution, I consider this as depthwise seperable convolution as mentioned in the class\n",
        "layer1 = SeparableConv2D(32,(5,5), strides=(1,1), padding = 'same',name= 'depthwise_1',use_bias=False)(input)\n",
        "layer1 = Dropout(0.2)(layer1)\n",
        "layer1 = BatchNormalization(name='norm_1')(layer1)\n",
        "layer1 = Activation('relu')(layer1)\n",
        "\n",
        "skip_connection1 = layer1\n",
        "\n",
        "#Normal 5,5 convolution\n",
        "layer2 = Conv2D(32, (5,5), strides=(1,1), padding='same', name='conv_1', use_bias=False,dilation_rate = 1)(layer1)\n",
        "layer2 = Dropout(0.2)(layer2)\n",
        "layer2 = BatchNormalization(name='norm_2')(layer2)\n",
        "layer2 = Activation('relu')(layer2)\n",
        "\n",
        "skip_connection2 = layer2\n",
        "\n",
        "#Nomal 5,5 convolution\n",
        "layer3 = Conv2D(64, (5,5), strides=(1,1), padding='same', name='conv_2', use_bias=False,dilation_rate = 1)(layer2)\n",
        "layer3 = Dropout(0.2)(layer3)\n",
        "layer3 = BatchNormalization(name='norm_3')(layer3)\n",
        "layer3 = Activation('relu')(layer3)\n",
        "\n",
        "skip_connection3 = layer3\n",
        "\n",
        "#matching the resolution to concatenate with layer3\n",
        "\n",
        "layerin = concatenate([layer3,skip_connection1])\n",
        "\n",
        "\n",
        "#5,5 seperable convolution, I consider this as depthwise seperable convolution as mentioned in the class\n",
        "layer4 = SeparableConv2D(128,(5,5), strides=(1,1), padding = 'same',name= 'depthwise_2',use_bias=False)(layerin)\n",
        "layer4 = Dropout(0.2)(layer4)\n",
        "layer4 = BatchNormalization(name='norm_4')(layer4)\n",
        "layer4 = Activation('relu')(layer4)\n",
        "\n",
        "skip_connection4 = layer4\n",
        "\n",
        "layerin1 = concatenate([layer4,skip_connection1])\n",
        "\n",
        "#Transition block\n",
        "layer5 = MaxPooling2D(pool_size=(2, 2))(layerin1)\n",
        "layer5 = Conv2D(32, (1,1),padding='same',use_bias=False)(layer5)\n",
        "layer5 = BatchNormalization(name='norm_5')(layer5)\n",
        "layer5 = Activation('relu')(layer5)\n",
        "\n",
        "#3,3 seperable convolutin,depthwise\n",
        "layer6 = SeparableConv2D(32,(3,3), strides=(1,1), padding = 'same',name= 'depthwise_3',use_bias=False)(layer5)\n",
        "layer6 = Dropout(0.2)(layer6)\n",
        "layer6 = BatchNormalization(name='norm_6')(layer6)\n",
        "layer6 = Activation('relu')(layer6)\n",
        "\n",
        "skip_connection6=layer6\n",
        "\n",
        "layerin2 = Lambda(space_to_depth_x2)(layerin1)\n",
        "layerin3=concatenate([layerin2,layer6])\n",
        "\n",
        "#5,5 normal convolution\n",
        "layer7 = Conv2D(64, (5,5), strides=(1,1), padding='same', name='conv_3', use_bias=False,dilation_rate = 1)(layerin3)\n",
        "layer7 = Dropout(0.2)(layer7)\n",
        "layer7 = BatchNormalization(name='norm_7')(layer7)\n",
        "layer7 = Activation('relu')(layer7)\n",
        "\n",
        "skip_connection7=layer7\n",
        "\n",
        "layerin4 =concatenate([skip_connection3,skip_connection4])\n",
        "layerin4 = Lambda(space_to_depth_x2)(layerin4)\n",
        "layerin5= concatenate([layerin4,skip_connection6])\n",
        "layerin5=concatenate([layerin5,layer7])\n",
        "\n",
        "#3,3 seperable convolution,depthwise\n",
        "layer8 = SeparableConv2D(64,(3,3), strides=(1,1), padding = 'same',name= 'depthwise_4',use_bias=False)(layerin5)\n",
        "layer8 = Dropout(0.2)(layer8)\n",
        "layer8 = BatchNormalization(name='norm_8')(layer8)\n",
        "layer8 = Activation('relu')(layer8)\n",
        "\n",
        "skip_connection8=layer8\n",
        "\n",
        "layerin6=concatenate([skip_connection1,skip_connection3])\n",
        "layerin7=concatenate([layerin6,skip_connection4])\n",
        "layerin7=Lambda(space_to_depth_x2)(layerin7)\n",
        "layerin8=concatenate([layerin7,skip_connection6])\n",
        "layerin9=concatenate([layerin8,skip_connection7])\n",
        "layerin9=concatenate([layerin9,layer8])\n",
        "\n",
        "##5,5sperable convolution,depthwise\n",
        "layer9 = SeparableConv2D(128,(5,5), strides=(1,1), padding = 'same',name= 'depthwise_5',use_bias=False)(layerin9)\n",
        "layer9 = Dropout(0.2)(layer9)\n",
        "layer9 = BatchNormalization(name='norm_9')(layer9)\n",
        "layer9 = Activation('relu')(layer9)\n",
        "\n",
        "skip_connection9= layer9\n",
        "\n",
        "layerin10=concatenate([layerin3,skip_connection8])\n",
        "layerin10=concatenate([layerin10,layer9])\n",
        "\n",
        "#Transition block\n",
        "layer10 = MaxPooling2D(pool_size=(2, 2))(layerin10)\n",
        "layer10 = Conv2D(32, (1,1),padding='same',use_bias=False)(layer10)\n",
        "layer10 = BatchNormalization(name='norm_10')(layer10)\n",
        "layer10 = Activation('relu')(layer10)\n",
        "\n",
        "skip_connection10=layer10\n",
        "\n",
        "layerin11=Lambda(space_to_depth_x2)(skip_connection7)\n",
        "layerin11=concatenate([layerin11,layer10])\n",
        "\n",
        "#5,5 normal convolutions\n",
        "layer11 = Conv2D(32, (5,5), strides=(1,1), padding='same', name='conv_4', use_bias=False,dilation_rate = 1)(layerin11)\n",
        "layer11 = Dropout(0.2)(layer11)\n",
        "layer11= BatchNormalization(name='norm_11')(layer11)\n",
        "layer11= Activation('relu')(layer11)\n",
        "\n",
        "skip_connection11=layer11\n",
        "\n",
        "layerin12=concatenate([skip_connection2,skip_connection4])\n",
        "layerin12=Lambda(space_to_depth_x2)(layerin12)\n",
        "layerin13=concatenate([layerin12,skip_connection8])\n",
        "layerin13=Lambda(space_to_depth_x2)(layerin13)\n",
        "layerin13=concatenate([layerin13,layer11])\n",
        "\n",
        "\n",
        "#5,5 seperable convolution,depthwise\n",
        "layer12 = SeparableConv2D(64,(5,5), strides=(1,1), padding = 'same',name= 'depthwise_6',use_bias=False)(layerin13)\n",
        "layer12 = Dropout(0.2)(layer12)\n",
        "layer12= BatchNormalization(name='norm_12')(layer12)\n",
        "layer12= Activation('relu')(layer12)\n",
        "\n",
        "skip_connection12=layer12\n",
        "\n",
        "layerin14=concatenate([skip_connection2,skip_connection3])\n",
        "layerin14=Lambda(space_to_depth_x2)(layerin14)\n",
        "layerin15=concatenate([layerin14,skip_connection6])\n",
        "layerin15=Lambda(space_to_depth_x2)(layerin15)\n",
        "layerin16=concatenate([layerin15,skip_connection11])\n",
        "layerin16=concatenate([layerin16,layer12])\n",
        "\n",
        "#3,3 normal convolutions\n",
        "layer13 = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False,dilation_rate = 1)(layerin16)\n",
        "layer13 = Dropout(0.2)(layer13)\n",
        "layer13= BatchNormalization(name='norm_13')(layer13)\n",
        "layer13= Activation('relu')(layer13)\n",
        "\n",
        "skip_connection13=layer13\n",
        "\n",
        "layerin17=concatenate([skip_connection1,skip_connection3])\n",
        "layerin18=concatenate([layerin17,skip_connection4])\n",
        "layerin18=Lambda(space_to_depth_x2)(layerin18)\n",
        "layerin19=concatenate([layerin18,skip_connection6])\n",
        "layerin20=concatenate([layerin19,skip_connection8])\n",
        "layerin20=Lambda(space_to_depth_x2)(layerin20)\n",
        "layerin21=concatenate([layerin20,skip_connection12])\n",
        "layerin21=concatenate([layerin21,layer13])\n",
        "\n",
        "#5,5 seperable convolution,depthwise\n",
        "layer14 = SeparableConv2D(128,(5,5), strides=(1,1), padding = 'same',name= 'depthwise_7',use_bias=False)(layerin21)\n",
        "layer14 = Dropout(0.2)(layer14)\n",
        "layer14= BatchNormalization(name='norm_14')(layer14)\n",
        "layer14= Activation('relu')(layer14)\n",
        "\n",
        "layerin22=Lambda(space_to_depth_x2)(skip_connection4)\n",
        "layerin23=concatenate([layerin22,skip_connection8])\n",
        "layerin23=Lambda(space_to_depth_x2)(layerin23)\n",
        "layerin24=concatenate([layerin23,skip_connection12])\n",
        "layerin24=concatenate([layerin24,layer14])\n",
        "\n",
        "layer15 = Conv2D(10, (1,1),padding='same',use_bias=False)(layerin24)\n",
        "layer15= Conv2D(10,8)(layer14)\n",
        "\n",
        "layer101 = Flatten()(layer15)\n",
        "output=Activation('softmax')(layer101)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0617 04:45:44.550073 140628864132992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0617 04:45:44.586013 140628864132992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0617 04:45:44.596272 140628864132992 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0617 04:45:44.623810 140628864132992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0617 04:45:47.501713 140628864132992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0617 04:45:47.842556 140628864132992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOix4vCqLQ_b",
        "colab_type": "code",
        "outputId": "eda7d273-2eb9-49dd-ba4d-5c82d0c9dbc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3893
        }
      },
      "source": [
        "\n",
        "from keras.models import Model\n",
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_1 (SeparableConv2D)   (None, 32, 32, 32)   171         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 32)   0           depthwise_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "norm_1 (BatchNormalization)     (None, 32, 32, 32)   128         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32)   0           norm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, 32, 32, 32)   25600       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 32)   0           conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "norm_2 (BatchNormalization)     (None, 32, 32, 32)   128         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 32)   0           norm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_2 (Conv2D)                 (None, 32, 32, 64)   51200       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 64)   0           conv_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "norm_3 (BatchNormalization)     (None, 32, 32, 64)   256         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 64)   0           norm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 96)   0           activation_3[0][0]               \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_2 (SeparableConv2D)   (None, 32, 32, 128)  14688       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 128)  0           depthwise_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "norm_4 (BatchNormalization)     (None, 32, 32, 128)  512         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 128)  0           norm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 160)  0           activation_4[0][0]               \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 160)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 16, 32)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_5 (BatchNormalization)     (None, 16, 16, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 32)   0           norm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_3 (SeparableConv2D)   (None, 16, 16, 32)   1312        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 16, 16, 32)   0           depthwise_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "norm_6 (BatchNormalization)     (None, 16, 16, 32)   128         dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 32)   0           norm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 16, 16, 640)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16, 16, 672)  0           lambda_1[0][0]                   \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_3 (Conv2D)                 (None, 16, 16, 64)   1075200     concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 192)  0           activation_3[0][0]               \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 16, 16, 64)   0           conv_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 16, 16, 768)  0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_7 (BatchNormalization)     (None, 16, 16, 64)   256         dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 16, 16, 800)  0           lambda_2[0][0]                   \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           norm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 16, 16, 864)  0           concatenate_5[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 96)   0           activation_1[0][0]               \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_4 (SeparableConv2D)   (None, 16, 16, 64)   63072       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 224)  0           concatenate_7[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 16, 16, 64)   0           depthwise_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 16, 16, 896)  0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_8 (BatchNormalization)     (None, 16, 16, 64)   256         dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 16, 16, 928)  0           lambda_3[0][0]                   \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           norm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 16, 16, 992)  0           concatenate_9[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 16, 16, 1056) 0           concatenate_10[0][0]             \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_5 (SeparableConv2D)   (None, 16, 16, 128)  161568      concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 16, 16, 128)  0           depthwise_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "norm_9 (BatchNormalization)     (None, 16, 16, 128)  512         dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 16, 16, 736)  0           concatenate_3[0][0]              \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 128)  0           norm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 16, 16, 864)  0           concatenate_12[0][0]             \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 864)    0           concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 8, 8, 32)     27648       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_10 (BatchNormalization)    (None, 8, 8, 32)     128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 8, 8, 256)    0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 32)     0           norm_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 8, 8, 288)    0           lambda_4[0][0]                   \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 160)  0           activation_2[0][0]               \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_4 (Conv2D)                 (None, 8, 8, 32)     230400      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 16, 16, 640)  0           concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 8, 8, 32)     0           conv_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 704)  0           lambda_5[0][0]                   \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "norm_11 (BatchNormalization)    (None, 8, 8, 32)     128         dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 8, 8, 2816)   0           concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 32)     0           norm_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 8, 8, 2848)   0           lambda_6[0][0]                   \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 32, 32, 96)   0           activation_2[0][0]               \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_6 (SeparableConv2D)   (None, 8, 8, 64)     253472      concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 16, 16, 384)  0           concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 8, 8, 64)     0           depthwise_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 416)  0           lambda_7[0][0]                   \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 32, 32, 96)   0           activation_1[0][0]               \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "norm_12 (BatchNormalization)    (None, 8, 8, 64)     256         dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 8, 8, 1664)   0           concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 32, 32, 224)  0           concatenate_22[0][0]             \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 64)     0           norm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 8, 8, 1696)   0           lambda_8[0][0]                   \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 16, 16, 896)  0           concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 8, 8, 1760)   0           concatenate_20[0][0]             \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 928)  0           lambda_9[0][0]                   \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_5 (Conv2D)                 (None, 8, 8, 64)     1013760     concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 992)  0           concatenate_24[0][0]             \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 8, 8, 64)     0           conv_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 8, 8, 3968)   0           concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_13 (BatchNormalization)    (None, 8, 8, 64)     256         dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 8, 8, 4032)   0           lambda_10[0][0]                  \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 64)     0           norm_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 8, 8, 4096)   0           concatenate_26[0][0]             \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_7 (SeparableConv2D)   (None, 8, 8, 128)    626688      concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 8, 8, 128)    0           depthwise_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "norm_14 (BatchNormalization)    (None, 8, 8, 128)    512         dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 128)    0           norm_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 1, 1, 10)     81930       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 10)           0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 10)           0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,635,413\n",
            "Trainable params: 3,633,621\n",
            "Non-trainable params: 1,792\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeUMI7jaNgEt",
        "colab_type": "code",
        "outputId": "43603ec6-a2ae-4e3d-8945-eee3274003c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0617 04:45:49.034957 140628864132992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aymPSUAon5wq",
        "colab_type": "code",
        "outputId": "b627f148-b07d-4eb4-d0d4-2c0cc4713292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3923
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128),\n",
        "                                 samples_per_epoch = train_features.shape[0], nb_epoch = 100, \n",
        "                                 validation_data = (test_features, test_labels), verbose=1)\n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n",
        "print (\"Accuracy on test data is: %0.2f\"%accuracy(test_features, test_labels, model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=100)`\n",
            "  if sys.path[0] == '':\n",
            "W0617 04:45:49.360032 140628864132992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 106s 271ms/step - loss: 1.5486 - acc: 0.4537 - val_loss: 1.7585 - val_acc: 0.4690\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 101s 259ms/step - loss: 1.0804 - acc: 0.6152 - val_loss: 1.1325 - val_acc: 0.6217\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 101s 259ms/step - loss: 0.8729 - acc: 0.6904 - val_loss: 1.6740 - val_acc: 0.5456\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.7407 - acc: 0.7404 - val_loss: 1.2224 - val_acc: 0.6540\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.6470 - acc: 0.7742 - val_loss: 1.0043 - val_acc: 0.6958\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.5645 - acc: 0.8030 - val_loss: 0.8416 - val_acc: 0.7494\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 103s 263ms/step - loss: 0.4970 - acc: 0.8254 - val_loss: 0.8301 - val_acc: 0.7463\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 103s 263ms/step - loss: 0.4303 - acc: 0.8488 - val_loss: 0.8724 - val_acc: 0.7454\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 103s 263ms/step - loss: 0.3705 - acc: 0.8693 - val_loss: 0.7728 - val_acc: 0.7715\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.3174 - acc: 0.8874 - val_loss: 0.8808 - val_acc: 0.7561\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.2758 - acc: 0.9026 - val_loss: 0.9254 - val_acc: 0.7567\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.2324 - acc: 0.9172 - val_loss: 0.9602 - val_acc: 0.7453\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.2027 - acc: 0.9282 - val_loss: 1.0562 - val_acc: 0.7566\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.1723 - acc: 0.9384 - val_loss: 0.9592 - val_acc: 0.7725\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.1545 - acc: 0.9442 - val_loss: 0.9917 - val_acc: 0.7787\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.1360 - acc: 0.9518 - val_loss: 0.9701 - val_acc: 0.7702\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.1227 - acc: 0.9571 - val_loss: 0.9537 - val_acc: 0.7944\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 103s 263ms/step - loss: 0.1135 - acc: 0.9594 - val_loss: 1.0807 - val_acc: 0.7840\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.1111 - acc: 0.9596 - val_loss: 1.0630 - val_acc: 0.7758\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.1049 - acc: 0.9628 - val_loss: 0.9008 - val_acc: 0.8076\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0865 - acc: 0.9699 - val_loss: 0.9228 - val_acc: 0.8057\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0877 - acc: 0.9686 - val_loss: 0.9570 - val_acc: 0.7921\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0799 - acc: 0.9722 - val_loss: 1.0524 - val_acc: 0.7972\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0847 - acc: 0.9700 - val_loss: 1.0334 - val_acc: 0.7937\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0793 - acc: 0.9716 - val_loss: 1.1035 - val_acc: 0.7932\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0743 - acc: 0.9738 - val_loss: 1.0461 - val_acc: 0.7944\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0679 - acc: 0.9762 - val_loss: 1.5336 - val_acc: 0.7457\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0697 - acc: 0.9749 - val_loss: 1.1100 - val_acc: 0.7887\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0659 - acc: 0.9772 - val_loss: 1.2679 - val_acc: 0.7863\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0609 - acc: 0.9788 - val_loss: 1.0578 - val_acc: 0.8047\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0640 - acc: 0.9776 - val_loss: 1.1868 - val_acc: 0.7922\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0538 - acc: 0.9810 - val_loss: 1.3544 - val_acc: 0.7635\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0562 - acc: 0.9809 - val_loss: 1.0936 - val_acc: 0.7988\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.0536 - acc: 0.9811 - val_loss: 1.1729 - val_acc: 0.7914\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0576 - acc: 0.9796 - val_loss: 1.1761 - val_acc: 0.7991\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0513 - acc: 0.9826 - val_loss: 1.1632 - val_acc: 0.8095\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0527 - acc: 0.9817 - val_loss: 1.1930 - val_acc: 0.7924\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0448 - acc: 0.9846 - val_loss: 1.1877 - val_acc: 0.7937\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0521 - acc: 0.9817 - val_loss: 1.2274 - val_acc: 0.7973\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0462 - acc: 0.9839 - val_loss: 1.4439 - val_acc: 0.7829\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0423 - acc: 0.9852 - val_loss: 1.1595 - val_acc: 0.8094\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0442 - acc: 0.9848 - val_loss: 1.2749 - val_acc: 0.7810\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0477 - acc: 0.9832 - val_loss: 1.2014 - val_acc: 0.8010\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.0432 - acc: 0.9853 - val_loss: 1.1560 - val_acc: 0.8035\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0408 - acc: 0.9859 - val_loss: 1.5214 - val_acc: 0.7719\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0377 - acc: 0.9874 - val_loss: 1.1477 - val_acc: 0.8061\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0416 - acc: 0.9853 - val_loss: 1.1642 - val_acc: 0.8138\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0405 - acc: 0.9859 - val_loss: 1.2423 - val_acc: 0.7938\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.0378 - acc: 0.9871 - val_loss: 1.3018 - val_acc: 0.8024\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0391 - acc: 0.9868 - val_loss: 1.2305 - val_acc: 0.8037\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0414 - acc: 0.9860 - val_loss: 1.1288 - val_acc: 0.8078\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0348 - acc: 0.9871 - val_loss: 1.2115 - val_acc: 0.8033\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0337 - acc: 0.9881 - val_loss: 1.1651 - val_acc: 0.8063\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0334 - acc: 0.9884 - val_loss: 1.1917 - val_acc: 0.8121\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0347 - acc: 0.9884 - val_loss: 1.1720 - val_acc: 0.8093\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0343 - acc: 0.9875 - val_loss: 1.2722 - val_acc: 0.8062\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0346 - acc: 0.9886 - val_loss: 1.1509 - val_acc: 0.8109\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.0327 - acc: 0.9890 - val_loss: 1.1293 - val_acc: 0.8175\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0317 - acc: 0.9884 - val_loss: 1.2689 - val_acc: 0.8058\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0329 - acc: 0.9885 - val_loss: 1.1376 - val_acc: 0.8103\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0323 - acc: 0.9887 - val_loss: 1.3423 - val_acc: 0.8025\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0321 - acc: 0.9894 - val_loss: 1.4015 - val_acc: 0.7910\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0302 - acc: 0.9895 - val_loss: 1.3401 - val_acc: 0.7955\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0314 - acc: 0.9891 - val_loss: 1.2806 - val_acc: 0.8020\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0286 - acc: 0.9897 - val_loss: 1.3719 - val_acc: 0.8000\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0302 - acc: 0.9891 - val_loss: 1.3018 - val_acc: 0.8057\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0286 - acc: 0.9906 - val_loss: 1.2458 - val_acc: 0.8133\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0292 - acc: 0.9900 - val_loss: 1.2700 - val_acc: 0.8070\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0299 - acc: 0.9898 - val_loss: 1.2579 - val_acc: 0.8034\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0259 - acc: 0.9912 - val_loss: 1.5291 - val_acc: 0.7905\n",
            "Epoch 71/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0262 - acc: 0.9910 - val_loss: 1.2660 - val_acc: 0.8122\n",
            "Epoch 72/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0309 - acc: 0.9899 - val_loss: 1.2829 - val_acc: 0.8098\n",
            "Epoch 73/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0238 - acc: 0.9921 - val_loss: 1.3095 - val_acc: 0.8153\n",
            "Epoch 74/100\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.0234 - acc: 0.9916 - val_loss: 1.2686 - val_acc: 0.8112\n",
            "Epoch 75/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0282 - acc: 0.9902 - val_loss: 1.2972 - val_acc: 0.8143\n",
            "Epoch 76/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0258 - acc: 0.9909 - val_loss: 1.3187 - val_acc: 0.8049\n",
            "Epoch 77/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0228 - acc: 0.9920 - val_loss: 1.2065 - val_acc: 0.8222\n",
            "Epoch 78/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0273 - acc: 0.9903 - val_loss: 1.4594 - val_acc: 0.7876\n",
            "Epoch 79/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0241 - acc: 0.9918 - val_loss: 1.2996 - val_acc: 0.8082\n",
            "Epoch 80/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.0269 - acc: 0.9910 - val_loss: 1.3710 - val_acc: 0.7956\n",
            "Epoch 81/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.0264 - acc: 0.9909 - val_loss: 1.4374 - val_acc: 0.7976\n",
            "Epoch 82/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0269 - acc: 0.9909 - val_loss: 1.2693 - val_acc: 0.8151\n",
            "Epoch 83/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.0243 - acc: 0.9921 - val_loss: 1.1831 - val_acc: 0.8225\n",
            "Epoch 84/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0240 - acc: 0.9915 - val_loss: 1.3464 - val_acc: 0.8114\n",
            "Epoch 85/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0212 - acc: 0.9930 - val_loss: 1.3764 - val_acc: 0.8075\n",
            "Epoch 86/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0251 - acc: 0.9917 - val_loss: 1.2556 - val_acc: 0.8198\n",
            "Epoch 87/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0255 - acc: 0.9917 - val_loss: 1.3828 - val_acc: 0.8086\n",
            "Epoch 88/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0205 - acc: 0.9934 - val_loss: 1.3282 - val_acc: 0.8135\n",
            "Epoch 89/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0216 - acc: 0.9929 - val_loss: 1.3053 - val_acc: 0.8176\n",
            "Epoch 90/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0264 - acc: 0.9906 - val_loss: 1.2701 - val_acc: 0.8182\n",
            "Epoch 91/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.0259 - acc: 0.9913 - val_loss: 1.2619 - val_acc: 0.8125\n",
            "Epoch 92/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0182 - acc: 0.9937 - val_loss: 1.2158 - val_acc: 0.8207\n",
            "Epoch 93/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.0200 - acc: 0.9931 - val_loss: 1.4709 - val_acc: 0.7955\n",
            "Epoch 94/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.0240 - acc: 0.9917 - val_loss: 1.2010 - val_acc: 0.8110\n",
            "Epoch 95/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.0190 - acc: 0.9934 - val_loss: 1.3196 - val_acc: 0.8123\n",
            "Epoch 96/100\n",
            "390/390 [==============================] - 102s 263ms/step - loss: 0.0209 - acc: 0.9928 - val_loss: 1.2464 - val_acc: 0.8169\n",
            "Epoch 97/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0229 - acc: 0.9924 - val_loss: 1.6532 - val_acc: 0.7815\n",
            "Epoch 98/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0252 - acc: 0.9914 - val_loss: 1.4061 - val_acc: 0.8024\n",
            "Epoch 99/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0195 - acc: 0.9934 - val_loss: 1.2519 - val_acc: 0.8151\n",
            "Epoch 100/100\n",
            "390/390 [==============================] - 102s 262ms/step - loss: 0.0167 - acc: 0.9942 - val_loss: 1.5259 - val_acc: 0.7956\n",
            "Model took 10227.68 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAFNCAYAAAC5cXZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVkV+j8OVCrQXgNkgQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data is: 79.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10XmNoyxmCdN",
        "colab_type": "text"
      },
      "source": [
        "##I changed the number of channels, just wanted to experiment what happens; by just keeping 32 and 64\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXoHy3Rzn99B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,SeparableConv2D\n",
        "from keras.layers import concatenate\n",
        "\n",
        "\n",
        "#5,5 seperable convolution, I consider this as depthwise seperable convolution as mentioned in the class\n",
        "layer1 = SeparableConv2D(32,(5,5), strides=(1,1), padding = 'same',name= 'depthwise_1',use_bias=False)(input)\n",
        "layer1 = Dropout(0.2)(layer1)\n",
        "layer1 = BatchNormalization(name='norm_1')(layer1)\n",
        "layer1 = Activation('relu')(layer1)\n",
        "\n",
        "skip_connection1 = layer1\n",
        "\n",
        "#Normal 5,5 convolution\n",
        "layer2 = Conv2D(32, (5,5), strides=(1,1), padding='same', name='conv_1', use_bias=False,dilation_rate = 1)(layer1)\n",
        "layer2 = Dropout(0.2)(layer2)\n",
        "layer2 = BatchNormalization(name='norm_2')(layer2)\n",
        "layer2 = Activation('relu')(layer2)\n",
        "\n",
        "skip_connection2 = layer2\n",
        "\n",
        "#Nomal 5,5 convolution\n",
        "layer3 = Conv2D(64, (5,5), strides=(1,1), padding='same', name='conv_2', use_bias=False,dilation_rate = 1)(layer2)\n",
        "layer3 = Dropout(0.2)(layer3)\n",
        "layer3 = BatchNormalization(name='norm_3')(layer3)\n",
        "layer3 = Activation('relu')(layer3)\n",
        "\n",
        "skip_connection3 = layer3\n",
        "\n",
        "#matching the resolution to concatenate with layer3\n",
        "\n",
        "layerin = concatenate([layer3,skip_connection1])\n",
        "\n",
        "\n",
        "#5,5 seperable convolution, I consider this as depthwise seperable convolution as mentioned in the class\n",
        "layer4 = SeparableConv2D(64,(5,5), strides=(1,1), padding = 'same',name= 'depthwise_2',use_bias=False)(layerin)\n",
        "layer4 = Dropout(0.2)(layer4)\n",
        "layer4 = BatchNormalization(name='norm_4')(layer4)\n",
        "layer4 = Activation('relu')(layer4)\n",
        "\n",
        "skip_connection4 = layer4\n",
        "\n",
        "layerin1 = concatenate([layer4,skip_connection1])\n",
        "\n",
        "#Transition block\n",
        "layer5 = MaxPooling2D(pool_size=(2, 2))(layerin1)\n",
        "layer5 = Conv2D(32, (1,1),padding='same',use_bias=False)(layer5)\n",
        "layer5 = BatchNormalization(name='norm_5')(layer5)\n",
        "layer5 = Activation('relu')(layer5)\n",
        "\n",
        "#3,3 seperable convolutin,depthwise\n",
        "layer6 = SeparableConv2D(32,(3,3), strides=(1,1), padding = 'same',name= 'depthwise_3',use_bias=False)(layer5)\n",
        "layer6 = Dropout(0.2)(layer6)\n",
        "layer6 = BatchNormalization(name='norm_6')(layer6)\n",
        "layer6 = Activation('relu')(layer6)\n",
        "\n",
        "skip_connection6=layer6\n",
        "\n",
        "layerin2 = Lambda(space_to_depth_x2)(layerin1)\n",
        "layerin3=concatenate([layerin2,layer6])\n",
        "\n",
        "#5,5 normal convolution\n",
        "layer7 = Conv2D(32, (5,5), strides=(1,1), padding='same', name='conv_3', use_bias=False,dilation_rate = 1)(layerin3)\n",
        "layer7 = Dropout(0.2)(layer7)\n",
        "layer7 = BatchNormalization(name='norm_7')(layer7)\n",
        "layer7 = Activation('relu')(layer7)\n",
        "\n",
        "skip_connection7=layer7\n",
        "\n",
        "layerin4 =concatenate([skip_connection3,skip_connection4])\n",
        "layerin4 = Lambda(space_to_depth_x2)(layerin4)\n",
        "layerin5= concatenate([layerin4,skip_connection6])\n",
        "layerin5=concatenate([layerin5,layer7])\n",
        "\n",
        "#3,3 seperable convolution,depthwise\n",
        "layer8 = SeparableConv2D(64,(3,3), strides=(1,1), padding = 'same',name= 'depthwise_4',use_bias=False)(layerin5)\n",
        "layer8 = Dropout(0.2)(layer8)\n",
        "layer8 = BatchNormalization(name='norm_8')(layer8)\n",
        "layer8 = Activation('relu')(layer8)\n",
        "\n",
        "skip_connection8=layer8\n",
        "\n",
        "layerin6=concatenate([skip_connection1,skip_connection3])\n",
        "layerin7=concatenate([layerin6,skip_connection4])\n",
        "layerin7=Lambda(space_to_depth_x2)(layerin7)\n",
        "layerin8=concatenate([layerin7,skip_connection6])\n",
        "layerin9=concatenate([layerin8,skip_connection7])\n",
        "layerin9=concatenate([layerin9,layer8])\n",
        "\n",
        "##5,5sperable convolution,depthwise\n",
        "layer9 = SeparableConv2D(64,(5,5), strides=(1,1), padding = 'same',name= 'depthwise_5',use_bias=False)(layerin9)\n",
        "layer9 = Dropout(0.2)(layer9)\n",
        "layer9 = BatchNormalization(name='norm_9')(layer9)\n",
        "layer9 = Activation('relu')(layer9)\n",
        "\n",
        "skip_connection9= layer9\n",
        "\n",
        "layerin10=concatenate([layerin3,skip_connection8])\n",
        "layerin10=concatenate([layerin10,layer9])\n",
        "\n",
        "#Transition block\n",
        "layer10 = MaxPooling2D(pool_size=(2, 2))(layerin10)\n",
        "layer10 = Conv2D(32, (1,1),padding='same',use_bias=False)(layer10)\n",
        "layer10 = BatchNormalization(name='norm_10')(layer10)\n",
        "layer10 = Activation('relu')(layer10)\n",
        "\n",
        "skip_connection10=layer10\n",
        "\n",
        "layerin11=Lambda(space_to_depth_x2)(skip_connection7)\n",
        "layerin11=concatenate([layerin11,layer10])\n",
        "\n",
        "#5,5 normal convolutions\n",
        "layer11 = Conv2D(32, (5,5), strides=(1,1), padding='same', name='conv_4', use_bias=False,dilation_rate = 1)(layerin11)\n",
        "layer11 = Dropout(0.2)(layer11)\n",
        "layer11= BatchNormalization(name='norm_11')(layer11)\n",
        "layer11= Activation('relu')(layer11)\n",
        "\n",
        "skip_connection11=layer11\n",
        "\n",
        "layerin12=concatenate([skip_connection2,skip_connection4])\n",
        "layerin12=Lambda(space_to_depth_x2)(layerin12)\n",
        "layerin13=concatenate([layerin12,skip_connection8])\n",
        "layerin13=Lambda(space_to_depth_x2)(layerin13)\n",
        "layerin13=concatenate([layerin13,layer11])\n",
        "\n",
        "\n",
        "#5,5 seperable convolution,depthwise\n",
        "layer12 = SeparableConv2D(32,(5,5), strides=(1,1), padding = 'same',name= 'depthwise_6',use_bias=False)(layerin13)\n",
        "layer12 = Dropout(0.2)(layer12)\n",
        "layer12= BatchNormalization(name='norm_12')(layer12)\n",
        "layer12= Activation('relu')(layer12)\n",
        "\n",
        "skip_connection12=layer12\n",
        "\n",
        "layerin14=concatenate([skip_connection2,skip_connection3])\n",
        "layerin14=Lambda(space_to_depth_x2)(layerin14)\n",
        "layerin15=concatenate([layerin14,skip_connection6])\n",
        "layerin15=Lambda(space_to_depth_x2)(layerin15)\n",
        "layerin16=concatenate([layerin15,skip_connection11])\n",
        "layerin16=concatenate([layerin16,layer12])\n",
        "\n",
        "#3,3 normal convolutions\n",
        "layer13 = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False,dilation_rate = 1)(layerin16)\n",
        "layer13 = Dropout(0.2)(layer13)\n",
        "layer13= BatchNormalization(name='norm_13')(layer13)\n",
        "layer13= Activation('relu')(layer13)\n",
        "\n",
        "skip_connection13=layer13\n",
        "\n",
        "layerin17=concatenate([skip_connection1,skip_connection3])\n",
        "layerin18=concatenate([layerin17,skip_connection4])\n",
        "layerin18=Lambda(space_to_depth_x2)(layerin18)\n",
        "layerin19=concatenate([layerin18,skip_connection6])\n",
        "layerin20=concatenate([layerin19,skip_connection8])\n",
        "layerin20=Lambda(space_to_depth_x2)(layerin20)\n",
        "layerin21=concatenate([layerin20,skip_connection12])\n",
        "layerin21=concatenate([layerin21,layer13])\n",
        "\n",
        "#5,5 seperable convolution,depthwise\n",
        "layer14 = SeparableConv2D(64,(5,5), strides=(1,1), padding = 'same',name= 'depthwise_7',use_bias=False)(layerin21)\n",
        "layer14 = Dropout(0.2)(layer14)\n",
        "layer14= BatchNormalization(name='norm_14')(layer14)\n",
        "layer14= Activation('relu')(layer14)\n",
        "\n",
        "layerin22=Lambda(space_to_depth_x2)(skip_connection4)\n",
        "layerin23=concatenate([layerin22,skip_connection8])\n",
        "layerin23=Lambda(space_to_depth_x2)(layerin23)\n",
        "layerin24=concatenate([layerin23,skip_connection12])\n",
        "layerin24=concatenate([layerin24,layer14])\n",
        "\n",
        "layer15 = Conv2D(10, (1,1),padding='same',use_bias=False)(layerin24)\n",
        "layer15= Conv2D(10,8)(layer14)\n",
        "\n",
        "layer101 = Flatten()(layer15)\n",
        "output=Activation('softmax')(layer101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbi9-5U8mZNL",
        "colab_type": "code",
        "outputId": "13f253ca-84aa-42f4-f356-ec16eecd06a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3893
        }
      },
      "source": [
        "from keras.models import Model\n",
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_1 (SeparableConv2D)   (None, 32, 32, 32)   171         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 32, 32, 32)   0           depthwise_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "norm_1 (BatchNormalization)     (None, 32, 32, 32)   128         dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 32)   0           norm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, 32, 32, 32)   25600       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 32, 32, 32)   0           conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "norm_2 (BatchNormalization)     (None, 32, 32, 32)   128         dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 32)   0           norm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_2 (Conv2D)                 (None, 32, 32, 64)   51200       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 32, 32, 64)   0           conv_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "norm_3 (BatchNormalization)     (None, 32, 32, 64)   256         dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 64)   0           norm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 32, 32, 96)   0           activation_18[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_2 (SeparableConv2D)   (None, 32, 32, 64)   8544        concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 32, 32, 64)   0           depthwise_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "norm_4 (BatchNormalization)     (None, 32, 32, 64)   256         dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 64)   0           norm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 32, 32, 96)   0           activation_19[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 96)   0           concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 32)   3072        max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_5 (BatchNormalization)     (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 32)   0           norm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_3 (SeparableConv2D)   (None, 16, 16, 32)   1312        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 16, 16, 32)   0           depthwise_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "norm_6 (BatchNormalization)     (None, 16, 16, 32)   128         dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 32)   0           norm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 16, 16, 384)  0           concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 16, 16, 416)  0           lambda_13[0][0]                  \n",
            "                                                                 activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_3 (Conv2D)                 (None, 16, 16, 32)   332800      concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 32, 32, 128)  0           activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 16, 16, 32)   0           conv_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_14 (Lambda)              (None, 16, 16, 512)  0           concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_7 (BatchNormalization)     (None, 16, 16, 32)   128         dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 16, 16, 544)  0           lambda_14[0][0]                  \n",
            "                                                                 activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 32)   0           norm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 16, 16, 576)  0           concatenate_35[0][0]             \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 32, 32, 96)   0           activation_16[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_4 (SeparableConv2D)   (None, 16, 16, 64)   42048       concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 32, 32, 160)  0           concatenate_37[0][0]             \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 16, 16, 64)   0           depthwise_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_15 (Lambda)              (None, 16, 16, 640)  0           concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_8 (BatchNormalization)     (None, 16, 16, 64)   256         dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 16, 16, 672)  0           lambda_15[0][0]                  \n",
            "                                                                 activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 64)   0           norm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 16, 16, 704)  0           concatenate_39[0][0]             \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 16, 16, 768)  0           concatenate_40[0][0]             \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_5 (SeparableConv2D)   (None, 16, 16, 64)   68352       concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 16, 16, 64)   0           depthwise_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "norm_9 (BatchNormalization)     (None, 16, 16, 64)   256         dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 16, 16, 480)  0           concatenate_33[0][0]             \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 64)   0           norm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 16, 16, 544)  0           concatenate_42[0][0]             \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 544)    0           concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 8, 8, 32)     17408       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_10 (BatchNormalization)    (None, 8, 8, 32)     128         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_16 (Lambda)              (None, 8, 8, 128)    0           activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 32)     0           norm_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 8, 8, 160)    0           lambda_16[0][0]                  \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 32, 32, 96)   0           activation_17[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_4 (Conv2D)                 (None, 8, 8, 32)     128000      concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_17 (Lambda)              (None, 16, 16, 384)  0           concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 8, 8, 32)     0           conv_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 16, 16, 448)  0           lambda_17[0][0]                  \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_11 (BatchNormalization)    (None, 8, 8, 32)     128         dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_18 (Lambda)              (None, 8, 8, 1792)   0           concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 32)     0           norm_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 8, 8, 1824)   0           lambda_18[0][0]                  \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 32, 32, 96)   0           activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_6 (SeparableConv2D)   (None, 8, 8, 32)     103968      concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_19 (Lambda)              (None, 16, 16, 384)  0           concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 8, 8, 32)     0           depthwise_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 16, 16, 416)  0           lambda_19[0][0]                  \n",
            "                                                                 activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 32, 32, 96)   0           activation_16[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_12 (BatchNormalization)    (None, 8, 8, 32)     128         dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_20 (Lambda)              (None, 8, 8, 1664)   0           concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 32, 32, 160)  0           concatenate_52[0][0]             \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 32)     0           norm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 8, 8, 1696)   0           lambda_20[0][0]                  \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_21 (Lambda)              (None, 16, 16, 640)  0           concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 8, 8, 1728)   0           concatenate_50[0][0]             \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 16, 16, 672)  0           lambda_21[0][0]                  \n",
            "                                                                 activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_5 (Conv2D)                 (None, 8, 8, 64)     995328      concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 16, 16, 736)  0           concatenate_54[0][0]             \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 8, 8, 64)     0           conv_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_22 (Lambda)              (None, 8, 8, 2944)   0           concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_13 (BatchNormalization)    (None, 8, 8, 64)     256         dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 8, 8, 2976)   0           lambda_22[0][0]                  \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 64)     0           norm_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 8, 8, 3040)   0           concatenate_56[0][0]             \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_7 (SeparableConv2D)   (None, 8, 8, 64)     270560      concatenate_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 8, 8, 64)     0           depthwise_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "norm_14 (BatchNormalization)    (None, 8, 8, 64)     256         dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 64)     0           norm_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 1, 1, 10)     40970       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 10)           0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 10)           0           flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,091,893\n",
            "Trainable params: 2,090,613\n",
            "Non-trainable params: 1,280\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOazKW7wmeAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-s_uFZMmhob",
        "colab_type": "code",
        "outputId": "507b3ade-0932-42d7-ee59-aae583abaf44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3872
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128),\n",
        "                                 samples_per_epoch = train_features.shape[0], nb_epoch = 100, \n",
        "                                 validation_data = (test_features, test_labels), verbose=1)\n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n",
        "print (\"Accuracy on test data is: %0.2f\"%accuracy(test_features, test_labels, model))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=100)`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 152s 390ms/step - loss: 1.5144 - acc: 0.4590 - val_loss: 1.6564 - val_acc: 0.4577\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 1.0921 - acc: 0.6136 - val_loss: 1.2132 - val_acc: 0.6042\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.8928 - acc: 0.6823 - val_loss: 1.1973 - val_acc: 0.6273\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.7589 - acc: 0.7337 - val_loss: 1.0307 - val_acc: 0.6806\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.6633 - acc: 0.7680 - val_loss: 0.9336 - val_acc: 0.7179\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.5849 - acc: 0.7965 - val_loss: 1.0087 - val_acc: 0.6882\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.5216 - acc: 0.8162 - val_loss: 1.1333 - val_acc: 0.6761\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.4675 - acc: 0.8351 - val_loss: 0.8524 - val_acc: 0.7385\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.4119 - acc: 0.8542 - val_loss: 0.7598 - val_acc: 0.7715\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 145s 372ms/step - loss: 0.3648 - acc: 0.8723 - val_loss: 0.9600 - val_acc: 0.7410\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.3246 - acc: 0.8862 - val_loss: 0.8354 - val_acc: 0.7621\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.2912 - acc: 0.8970 - val_loss: 0.8019 - val_acc: 0.7739\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.2593 - acc: 0.9073 - val_loss: 0.7573 - val_acc: 0.7971\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.2293 - acc: 0.9183 - val_loss: 1.0413 - val_acc: 0.7685\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.2105 - acc: 0.9257 - val_loss: 0.8367 - val_acc: 0.7879\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.1834 - acc: 0.9351 - val_loss: 1.0517 - val_acc: 0.7661\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 144s 368ms/step - loss: 0.1643 - acc: 0.9412 - val_loss: 1.0983 - val_acc: 0.7571\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.1616 - acc: 0.9428 - val_loss: 0.8900 - val_acc: 0.7924\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.1412 - acc: 0.9497 - val_loss: 0.9210 - val_acc: 0.7910\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.1364 - acc: 0.9513 - val_loss: 1.0084 - val_acc: 0.7918\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.1280 - acc: 0.9545 - val_loss: 1.0715 - val_acc: 0.7870\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.1195 - acc: 0.9578 - val_loss: 1.2325 - val_acc: 0.7611\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.1154 - acc: 0.9589 - val_loss: 1.0853 - val_acc: 0.7896\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.1075 - acc: 0.9618 - val_loss: 0.9732 - val_acc: 0.8020\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.1034 - acc: 0.9640 - val_loss: 0.9137 - val_acc: 0.8104\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0994 - acc: 0.9647 - val_loss: 1.1879 - val_acc: 0.7698\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0905 - acc: 0.9674 - val_loss: 1.0758 - val_acc: 0.7984\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.0866 - acc: 0.9693 - val_loss: 1.0516 - val_acc: 0.8016\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0847 - acc: 0.9698 - val_loss: 1.2017 - val_acc: 0.7793\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0818 - acc: 0.9714 - val_loss: 1.1190 - val_acc: 0.8058\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0810 - acc: 0.9711 - val_loss: 1.1879 - val_acc: 0.7894\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0818 - acc: 0.9706 - val_loss: 1.0511 - val_acc: 0.8042\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0774 - acc: 0.9725 - val_loss: 1.3495 - val_acc: 0.7698\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0760 - acc: 0.9728 - val_loss: 0.9690 - val_acc: 0.8129\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0724 - acc: 0.9752 - val_loss: 1.3165 - val_acc: 0.7814\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0750 - acc: 0.9742 - val_loss: 1.0428 - val_acc: 0.8049\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0643 - acc: 0.9769 - val_loss: 0.9875 - val_acc: 0.8073\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0654 - acc: 0.9774 - val_loss: 1.5720 - val_acc: 0.7505\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0636 - acc: 0.9775 - val_loss: 1.3796 - val_acc: 0.7826\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0641 - acc: 0.9774 - val_loss: 1.1624 - val_acc: 0.8029\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0644 - acc: 0.9773 - val_loss: 1.3336 - val_acc: 0.7792\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0580 - acc: 0.9796 - val_loss: 1.2299 - val_acc: 0.7965\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0603 - acc: 0.9792 - val_loss: 1.2845 - val_acc: 0.7993\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.0616 - acc: 0.9785 - val_loss: 1.0851 - val_acc: 0.8073\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.0567 - acc: 0.9802 - val_loss: 1.0815 - val_acc: 0.8072\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.0561 - acc: 0.9806 - val_loss: 1.3945 - val_acc: 0.7868\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.0546 - acc: 0.9812 - val_loss: 1.1807 - val_acc: 0.8016\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0546 - acc: 0.9807 - val_loss: 1.1675 - val_acc: 0.8065\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0466 - acc: 0.9838 - val_loss: 1.1643 - val_acc: 0.8082\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0527 - acc: 0.9817 - val_loss: 1.4434 - val_acc: 0.7638\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0526 - acc: 0.9808 - val_loss: 1.1100 - val_acc: 0.8163\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0487 - acc: 0.9825 - val_loss: 1.2549 - val_acc: 0.7892\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0473 - acc: 0.9832 - val_loss: 1.1282 - val_acc: 0.8185\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0463 - acc: 0.9835 - val_loss: 1.1253 - val_acc: 0.8201\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0511 - acc: 0.9819 - val_loss: 1.1184 - val_acc: 0.8082\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 144s 368ms/step - loss: 0.0490 - acc: 0.9825 - val_loss: 1.2180 - val_acc: 0.8060\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0466 - acc: 0.9832 - val_loss: 1.2201 - val_acc: 0.8057\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0440 - acc: 0.9851 - val_loss: 1.1637 - val_acc: 0.8094\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0422 - acc: 0.9855 - val_loss: 1.3973 - val_acc: 0.7891\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0469 - acc: 0.9835 - val_loss: 1.0430 - val_acc: 0.8192\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.0402 - acc: 0.9864 - val_loss: 1.1955 - val_acc: 0.8214\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0406 - acc: 0.9858 - val_loss: 1.2703 - val_acc: 0.8051\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0439 - acc: 0.9843 - val_loss: 1.1305 - val_acc: 0.8159\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0417 - acc: 0.9851 - val_loss: 1.2464 - val_acc: 0.7976\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0407 - acc: 0.9857 - val_loss: 1.1108 - val_acc: 0.8215\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0382 - acc: 0.9872 - val_loss: 1.1624 - val_acc: 0.8195\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0395 - acc: 0.9858 - val_loss: 1.1557 - val_acc: 0.8126\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0426 - acc: 0.9850 - val_loss: 1.3017 - val_acc: 0.8046\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0381 - acc: 0.9866 - val_loss: 1.2208 - val_acc: 0.8131\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0355 - acc: 0.9878 - val_loss: 1.2861 - val_acc: 0.8007\n",
            "Epoch 71/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0366 - acc: 0.9878 - val_loss: 1.2471 - val_acc: 0.8125\n",
            "Epoch 72/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0408 - acc: 0.9864 - val_loss: 1.4508 - val_acc: 0.7951\n",
            "Epoch 73/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0412 - acc: 0.9858 - val_loss: 1.2555 - val_acc: 0.7967\n",
            "Epoch 74/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0371 - acc: 0.9870 - val_loss: 1.2992 - val_acc: 0.8000\n",
            "Epoch 75/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0360 - acc: 0.9876 - val_loss: 1.3611 - val_acc: 0.7918\n",
            "Epoch 76/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0337 - acc: 0.9882 - val_loss: 1.1554 - val_acc: 0.8222\n",
            "Epoch 77/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0333 - acc: 0.9886 - val_loss: 1.2161 - val_acc: 0.8079\n",
            "Epoch 78/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0360 - acc: 0.9870 - val_loss: 1.2031 - val_acc: 0.8204\n",
            "Epoch 79/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0347 - acc: 0.9880 - val_loss: 1.2464 - val_acc: 0.8168\n",
            "Epoch 80/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0346 - acc: 0.9881 - val_loss: 1.7162 - val_acc: 0.7513\n",
            "Epoch 81/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0340 - acc: 0.9877 - val_loss: 1.1700 - val_acc: 0.8082\n",
            "Epoch 82/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0352 - acc: 0.9873 - val_loss: 1.3063 - val_acc: 0.7994\n",
            "Epoch 83/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0349 - acc: 0.9877 - val_loss: 1.1846 - val_acc: 0.8274\n",
            "Epoch 84/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0338 - acc: 0.9883 - val_loss: 1.2739 - val_acc: 0.7990\n",
            "Epoch 85/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0344 - acc: 0.9881 - val_loss: 1.3977 - val_acc: 0.7955\n",
            "Epoch 86/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0334 - acc: 0.9882 - val_loss: 1.1770 - val_acc: 0.8153\n",
            "Epoch 87/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0305 - acc: 0.9896 - val_loss: 1.3348 - val_acc: 0.8108\n",
            "Epoch 88/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0314 - acc: 0.9890 - val_loss: 1.2634 - val_acc: 0.8088\n",
            "Epoch 89/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0338 - acc: 0.9882 - val_loss: 1.1982 - val_acc: 0.8137\n",
            "Epoch 90/100\n",
            "390/390 [==============================] - 144s 369ms/step - loss: 0.0295 - acc: 0.9902 - val_loss: 1.1921 - val_acc: 0.8195\n",
            "Epoch 91/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0302 - acc: 0.9897 - val_loss: 1.2350 - val_acc: 0.7992\n",
            "Epoch 92/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0309 - acc: 0.9888 - val_loss: 1.2165 - val_acc: 0.8091\n",
            "Epoch 93/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.0332 - acc: 0.9886 - val_loss: 1.2755 - val_acc: 0.8118\n",
            "Epoch 94/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.0293 - acc: 0.9897 - val_loss: 1.2297 - val_acc: 0.8076\n",
            "Epoch 95/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0307 - acc: 0.9890 - val_loss: 1.2421 - val_acc: 0.8189\n",
            "Epoch 96/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0289 - acc: 0.9899 - val_loss: 1.2927 - val_acc: 0.8169\n",
            "Epoch 97/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0258 - acc: 0.9910 - val_loss: 1.1865 - val_acc: 0.8253\n",
            "Epoch 98/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.0266 - acc: 0.9912 - val_loss: 1.2558 - val_acc: 0.8168\n",
            "Epoch 99/100\n",
            "390/390 [==============================] - 145s 371ms/step - loss: 0.0278 - acc: 0.9899 - val_loss: 1.1778 - val_acc: 0.8171\n",
            "Epoch 100/100\n",
            "390/390 [==============================] - 144s 370ms/step - loss: 0.0303 - acc: 0.9897 - val_loss: 1.3013 - val_acc: 0.8174\n",
            "Model took 14437.81 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAFNCAYAAAC5cXZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzMzM2tB/wWs37z8Rj9ErQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data is: 81.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zWS5I09mmX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}